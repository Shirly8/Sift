# Sift â€” Agentic Spending Intelligence

Analyzes personal transaction data to surface compound insights across five statistical tools. Adapts to your data â€” skips analyses when data is insufficient, cross-references results across tools, and routes follow-up questions to real computations (not LLM guesses).


## Architecture

```mermaid
flowchart TD
    CSV(["ğŸ“„ CSV Upload"])

    subgraph INGEST["  Ingestion  "]
        direction LR
        I1["Format<br/>Detect"] --> I2["Normalize"] --> I3["Dedupe"] --> I4["Quality<br/>Score"]
    end

    subgraph CAT["  Categorization  "]
        direction LR
        C1["Rules Engine<br/>70%+ Â· $0"] -->|miss| C2["Merchant<br/>Cache"] -->|miss| C3["LLM<br/>Fallback"]
    end

    subgraph ORCH["  Agent Orchestrator  "]
        direction LR
        O1["â‘  Profile<br/>Data"] --> O2["â‘¡ Plan<br/>Tools"] --> O3["â‘¢ Execute"]
    end

    subgraph TOOLS["  Statistical Tools  "]
        direction TB
        T1["ğŸ• Temporal<br/>payday Â· weekly Â· seasonal<br/>â‰¥ 90 days"]
        T2["ğŸ” Anomaly<br/>outliers Â· spikes Â· new merchants<br/>no minimum"]
        T3["ğŸ”„ Subscriptions<br/>recurring Â· price creep Â· overlap<br/>â‰¥ 100 txns"]
        T4["ğŸ“Š Correlations<br/>Pearson + Bonferroni<br/>â‰¥ 90 days Â· 3 categories"]
        T5["ğŸ’¡ Spending Impact<br/>std-deviation ranking<br/>â‰¥ 180 days Â· 5 categories"]
    end

    subgraph SYNTH["  Synthesizer  "]
        direction LR
        S1["Cross-reference<br/>Tools"] --> S2["Rank by<br/>$ Impact"] --> S3["3â€“5<br/>Insights"]
    end

    subgraph CONV["  Conversational Agent  "]
        direction LR
        Q1["Route<br/>Question"] --> Q2["Run<br/>Computation"] --> Q3["LLM<br/>Explains"]
    end

    LLM(["ğŸ¤– LLM Client<br/>Claude Â· OpenAI Â· Gemini Â· Ollama"])

    %% Main pipeline
    CSV --> INGEST --> CAT --> ORCH --> TOOLS --> SYNTH

    %% Conversational loop
    SYNTH -->|insights| DASH(["ğŸ“± Dashboard"])
    DASH -->|follow-up question| CONV
    CONV -->|answer| DASH

    %% LLM usage â€” sparse, dashed
    C3 -.->|categorize ambiguous| LLM
    SYNTH -.->|synthesize insights| LLM
    Q1 -.->|route + explain| LLM

    %% Styles â€” terracotta as backgrounds, warm cream text
    classDef section fill:#b85c38,stroke:#7a3018,color:#fff5ee
    classDef innernode fill:#f5e0cc,stroke:#c06040,color:#3a1500
    classDef endpoint fill:#e8783a,stroke:#9a3c10,color:#fff5ee
    classDef llmnode fill:#d4944a,stroke:#9a6020,color:#3a1500

    class INGEST,CAT,ORCH,TOOLS,SYNTH,CONV section
    class I1,I2,I3,I4,C1,C2,C3,O1,O2,O3,T1,T2,T3,T4,T5,S1,S2,S3,Q1,Q2,Q3 innernode
    class CSV,DASH endpoint
    class LLM llmnode
```

### Interface
![alt text](image.png)

### LLM Providers
Claude, OpenAI, Gemini, local Ollama


## Design Decisions

**Rules-first, not AI-first** â€” Rules handle 70%+ of merchants at zero cost. LLM only sees genuinely ambiguous cases. With financial analysis scaling (~1M users), ~$1.4M/month saved vs classifying everything with LLM.

**Std ranking over regression for spending impact** â€” Linear regression where Y = sum of X is tautological (RÂ² always ~1.0). Standard deviation ranking measures variance contribution honestly.

**Bonferroni correction on correlations** â€” With N categories there are N(N-1)/2 pairs to test. Uncorrected testing inflates false positives. Bonferroni ensures only robust correlations surface.
